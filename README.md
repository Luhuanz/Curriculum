# Curriculum
## djangoç½‘å€éƒ¨ç½²åˆ°é˜¿é‡Œäº‘ä¸Š :http://47.101.195.146/
## è¯¾ç¨‹è®¾è®¡æ€»æ¦‚

è¯¥é¡¹ç›®ä»¥ç½‘ç»œçˆ¬è™«è¿›è¡Œæ•°æ®é‡‡é›†ï¼Œåˆ©ç”¨pandaså’Œnumpyå¯¹æ•°æ®è¿›è¡Œæ¸…æ´—ã€‚éšåï¼Œä½¿ç”¨Tableauä»ªè¡¨ç›˜å¯¹æ¸…æ´—åçš„æ•°æ®è¿›è¡Œå¯è§†åŒ–å‘ˆç°ã€‚å¯¹ä»æ•°æ®ä¸­æå–çš„ä¿¡æ¯ï¼Œè¿›è¡ŒçŸ¥è¯†å›¾è°±çš„æ„å»ºï¼Œå¹¶å®ç°QAé—®ç­”ç³»ç»Ÿã€‚æ¥ä¸‹æ¥ï¼ŒåŸºäºæ•°æ®å±æ€§ï¼Œå¯¹å®å¯æ¢¦å¤šè½®å¯¹è¯å¤§æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚æœ€ç»ˆé˜¶æ®µï¼Œé¡¹ç›®åˆ©ç”¨å®å¯æ¢¦çš„å›¾ç‰‡è¿›è¡ŒCLIPè·¨æ¨¡æ€æ¢ç´¢ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ã€‚è¿™æ•´ä¸ªè¿‡ç¨‹èåˆäº†æ•°æ®é‡‡é›†ã€æ¸…æ´—ã€å¯è§†åŒ–ã€çŸ¥è¯†å›¾è°±æ„å»ºã€QAç³»ç»Ÿã€æ¨¡å‹å¾®è°ƒå’Œè·¨æ¨¡æ€æ¢ç´¢ï¼Œå½¢æˆä¸€ä¸ªå…¨é¢è€Œå¤šå±‚æ¬¡çš„æ•°æ®ç§‘å­¦é¡¹ç›®ã€‚

## ç²¾çµå®å¯æ¢¦çˆ¬è™« :video_game:

è¿™æ˜¯ä¸€ä¸ªç²¾çµå®å¯æ¢¦çˆ¬è™«é¡¹ç›®ï¼Œç”¨äºè·å–æœ‰å…³ç²¾çµå®å¯æ¢¦çš„ä¿¡æ¯å’Œå›¾ç‰‡ã€‚

### çˆ¬å–çš„ç½‘é¡µ :laughing:

- [ç²¾çµå®å¯æ¢¦å®˜æ–¹ç½‘ç«™](https://tw.portal-pokemon.com/play/pokedex/0001)

### é¡¹ç›®æ–‡ä»¶ :file_folder:

- `pokemon.py` :file_folder:ï¼šæºä»£ç æ–‡ä»¶ï¼Œç”¨äºæ‰§è¡Œçˆ¬è™«æ“ä½œã€‚
- `imgs` :heart_eyes: :file_folder:ï¼šå­˜å‚¨çˆ¬å–çš„ç²¾çµå®å¯æ¢¦å›¾ç‰‡ï¼Œå‘½åæ ¼å¼ä¸º "åºå·+å§“å+æ–‡ä»¶å"ï¼Œä¾‹å¦‚ï¼š`0001å¦™è›™ç¨®å­.png`ã€‚

### æ•°æ®æ–‡ä»¶ :bar_chart:

- `pokemon.csv` :joy: :file_folder:ï¼šç”± `pokemon.py` ç”Ÿæˆçš„åŸå§‹æ•°æ®æ–‡ä»¶ã€‚
- `pokemon_excel.csv` :file_folder:ï¼šä½¿ç”¨ Excel å¯¹ `pokemon.csv` è¿›è¡Œåˆæ­¥ç­›é€‰å’Œå¤„ç†çš„æ•°æ®æ–‡ä»¶ã€‚

### ä¼˜åŒ– :rocket:

è¿™ä¸ªé¡¹ç›®çš„ç›®æ ‡æ˜¯æ”¶é›†ç²¾çµå®å¯æ¢¦çš„ä¿¡æ¯å’Œå›¾ç‰‡ã€‚ä½ å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–é¡¹ç›®ï¼ŒåŒ…æ‹¬ï¼š

- æ·»åŠ æ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹æ­¥éª¤ï¼Œä»¥æé«˜æ•°æ®è´¨é‡ã€‚
- åˆ›å»ºæ•°æ®å¯è§†åŒ–ä»¥åˆ†æå’Œå±•ç¤ºæœ‰è¶£çš„ä¿¡æ¯ã€‚
- è‡ªåŠ¨åŒ–çˆ¬è™«ï¼Œä»¥å®šæœŸè·å–æœ€æ–°çš„ç²¾çµå®å¯æ¢¦æ•°æ®ã€‚
- ä¸ºæ•°æ®æ–‡ä»¶æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å’Œæ³¨é‡Šï¼Œä½¿å…¶ä»–äººå¯ä»¥ç†è§£å’Œä½¿ç”¨æ•°æ®ã€‚

æ¬¢è¿éšæ—¶æ‰©å±•å’Œæ”¹è¿›è¿™ä¸ªé¡¹ç›®ï¼Œä»¥æ»¡è¶³ä½ çš„éœ€æ±‚å’Œå…´è¶£ã€‚ç¥ä½ åœ¨è¿™ä¸ªç²¾çµå®å¯æ¢¦çˆ¬è™«é¡¹ç›®ä¸­å–å¾—æˆåŠŸï¼ :tada:



## æ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹ :muscle:

### ç›®å½•ç»“æ„ :file_folder:

#### Data_cleaning

- `data_processing.csv` :file_folder:ï¼šç»è¿‡æ•°æ®å¤„ç†çš„æ–‡ä»¶
- `pokemon_excel.csv` :file_folder:ï¼šä»çˆ¬è™«è·å–çš„æ–‡ä»¶
- `æ¸…æ´—.ipynb` :file_folder:ï¼šæ•°æ®æ¸…æ´—çš„Jupyter Notebookæ–‡ä»¶

#### Data Visualization

- `data+` (å¤šä¸ªè¿æ¥).hyper :file_folder:ï¼šåŒ…å«å¤šä¸ªæ•°æ®è¿æ¥çš„Hyperæ–‡ä»¶
- `data.csv` :file_folder:ï¼šä¸ `data_processing.csv` ç›¸åŒçš„æ•°æ®æ–‡ä»¶
- `data.xlsx` :file_folder:ï¼šä¸ `data_processing.csv` ç›¸åŒçš„æ•°æ®æ–‡ä»¶ï¼ˆExcelæ ¼å¼ï¼‰
- `ä½“é‡è¶…è¿‡10kg.xlsx` :file_folder:ï¼šåŒ…å«ä½“é‡è¶…è¿‡10kgçš„æ•°æ®ï¼ˆExcelæ ¼å¼ï¼‰
- `å±æ€§å’Œå¼±ç‚¹åˆ†æ.xls` :file_folder:ï¼šåŒ…å«å±æ€§å’Œå¼±ç‚¹åˆ†æçš„æ•°æ®ï¼ˆExcelæ ¼å¼ï¼‰
- `å¹³å‡èº«é«˜.xlsx` :file_folder:ï¼šåŒ…å«å¹³å‡èº«é«˜æ•°æ®ï¼ˆExcelæ ¼å¼ï¼‰
- `æŸ¥è¯¢.sql` :file_folder:ï¼šåŒ…å«SQLæŸ¥è¯¢çš„æ–‡ä»¶
- `ç‰¹å®šå¼±ç‚¹ç«çš„è§’è‰²è¯¦ç»†ä¿¡æ¯.xlsx` :file_folder:ï¼šåŒ…å«ç‰¹å®šå¼±ç‚¹ç«å±æ€§çš„è§’è‰²è¯¦ç»†ä¿¡æ¯ï¼ˆExcelæ ¼å¼ï¼‰
- `ç”»å›¾.twb` :file_folder:ï¼šä½¿ç”¨ Tableau è¿›è¡Œæ•°æ®å¯è§†åŒ–çš„æ–‡ä»¶
- `èº«é«˜ä½“é‡æ¯”ç‡.xlsx` :file_folder:ï¼šåŒ…å«èº«é«˜ä½“é‡æ¯”ç‡æ•°æ®ï¼ˆExcelæ ¼å¼ï¼‰

### æ–‡ä»¶è¯¦è§£ :runner:

- `pokemon_excel.csv` :two_hearts:ï¼šè¿™æ˜¯ä»çˆ¬è™«è·å–çš„æ•°æ®æ–‡ä»¶ã€‚
- `data_processing.csv` :v:ï¼šè¿™æ˜¯ç»è¿‡ä½¿ç”¨ NumPy å’Œ Pandas è¿›è¡ŒåŸºæœ¬æ•°æ®å¤„ç†çš„æ–‡ä»¶ã€‚
- `data.csv` / `data.xlsx` :v:ï¼šè¿™ä¸¤ä¸ªæ–‡ä»¶åŒ…å«ç›¸åŒçš„æ•°æ®ï¼Œåˆ†åˆ«ä»¥ CSV å’Œ Excel æ ¼å¼æä¾›ã€‚
- `æŸ¥è¯¢.sql` :person_with_pouting_face:: è¿™æ˜¯åŒ…å« SQL æŸ¥è¯¢çš„æ–‡ä»¶ï¼Œç”¨äºæ•°æ®åˆ†æã€‚
- `ç”»å›¾.twb` :smile:: è¿™ä¸ªæ–‡ä»¶åŒ…å«äº†ä½¿ç”¨ Tableau è¿›è¡Œçš„æ•°æ®å¯è§†åŒ–ï¼Œä½ å¯ä»¥åœ¨ [Tableau æ•°æ®å¯è§†åŒ–](https://public.tableau.com/app/profile/luhuanz.lu/viz/Coursedesigndatavisualization/1) ä¸ŠæŸ¥çœ‹ã€‚

![æ•°æ®å¯è§†åŒ–](./2. Feature Engineering & Data Visualization/readme.assets/vis-17049423328011.png)

  

## çŸ¥è¯†å›¾è°± & é—®ç­” :punch:

è¿™ä¸ªé¡¹ç›®æ¶‰åŠåˆ°çŸ¥è¯†å›¾è°±æ„å»ºå’Œå®å¯æ¢¦é—®ç­”ç³»ç»Ÿçš„å¼€å‘ã€‚

### ç›®å½•è·¯å¾„ :raised_hands:

```plaintext
â”€ KG
â”‚   data.csv
â”‚   graph.png
â”‚   ç‰¹å¾kg.txt
â”‚   è¿›åŒ–kg.txt
â”‚
â””â”€KGQA
        pk_qa.py
        qa.py
            
```

- ### æ–‡ä»¶åç§° :walking:

  - `ç‰¹å¾kg.txt` :file_folder:ï¼šä» `data.csv` ä¸­æŠ½å–çš„ç‰¹å¾çŸ¥è¯†å›¾è°±å®ä½“ã€‚
  - `è¿›åŒ–kg.txt` :file_folder:ï¼šä» `data.csv` ä¸­æŠ½å–çš„è¿›åŒ–çŸ¥è¯†å›¾è°±å®ä½“ã€‚
  - `build_graph_pk.py` :file_folder:ï¼šç”¨äºä½¿ç”¨ Neo4j æ•°æ®åº“æ„å»ºçŸ¥è¯†å›¾è°±çš„è„šæœ¬ã€‚
  - `pk_qa.py` :file_folder:ï¼šå®å¯æ¢¦é—®ç­”æ¥å£çš„å®ç°è„šæœ¬ã€‚
  - `qa.py` :file_folder:ï¼šå®ç°å¤šè½®å¯¹è¯çš„è„šæœ¬ã€‚

### å›¾è°±æ¦‚è§ˆ



<img src="README.assets/graph.png" alt="graph" style="zoom: 33%;" />

#### ä½¿ç”¨neo4j æŸ¥è¯¢å®ä½“ "çš®å¡ä¸˜":heart_eyes:



![kg](README.assets/kg.gif)



### å®å¯æ¢¦Q&Aé—®ç­” 

![kgqa](README.assets/kgqa.gif)

### ä¼˜åŒ– :rocket:

è¿™ä¸ªé¡¹ç›®åŒ…æ‹¬æ„å»ºçŸ¥è¯†å›¾è°±å’Œå®å¯æ¢¦é—®ç­”ç³»ç»Ÿã€‚ä½ å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–é¡¹ç›®ï¼ŒåŒ…æ‹¬ï¼š

- æ‰©å±•çŸ¥è¯†å›¾è°±ä»¥åŒ…æ‹¬æ›´å¤šå®ä½“å’Œå…³ç³»ã€‚
- æé«˜é—®ç­”ç³»ç»Ÿçš„å‡†ç¡®æ€§å’Œäº¤äº’æ€§ã€‚
- æ·»åŠ æ›´å¤šåŠŸèƒ½ï¼Œå¦‚å¤šè¯­è¨€æ”¯æŒæˆ–å®æ—¶æŸ¥è¯¢ã€‚
- å®šæœŸç»´æŠ¤å’Œæ›´æ–°çŸ¥è¯†å›¾è°± ã€‚





## ChatGLM3-6B å¤šè½®å¯¹è¯å¾®è°ƒå®å¯æ¢¦æ•°æ®é›† ğŸš€

è¿™ä¸ªé¡¹ç›®æ˜¯åŸºäº [ChatGLM3](https://github.com/THUDM/ChatGLM3) çš„æ‰©å±•ï¼Œä¸“æ³¨äºåˆ©ç”¨å®å¯æ¢¦æ•°æ®é›†å¯¹èŠå¤©æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬ä½¿ç”¨ RTX 4090 24G è¿›è¡Œè®­ç»ƒï¼Œç¡®ä¿é«˜æ•ˆçš„æ¨¡å‹æ€§èƒ½

### ç¯å¢ƒå®‰è£… ğŸ› ï¸

é¦–å…ˆéœ€è¦ä¸‹è½½ChatGLM3-6B å®˜æ–¹ä»“åº“ï¼š

```git
git clone https://github.com/THUDM/ChatGLM3
cd ChatGLM3
```

ç„¶åä½¿ç”¨ pip å®‰è£…ä¾èµ–ï¼š

```python
pip install -r requirements.txt
```



**æ›¿æ¢ `finetune_chatmodel_demo` æ–‡ä»¶å¤¹**: å°†å®˜æ–¹çš„ `finetune_chatmodel_demo` æ–‡ä»¶å¤¹æ›¿æ¢ä¸ºæœ¬é¡¹ç›®æä¾›çš„ç‰ˆæœ¬ã€‚

è¿è¡Œç¤ºä¾‹éœ€è¦ `python>=3.10`ï¼Œé™¤åŸºç¡€çš„ `torch` ä¾èµ–å¤–ï¼Œç¤ºä¾‹ä»£ç è¿è¡Œè¿˜éœ€è¦ä¾èµ–

```python
pip install requirements.txt
```



 è¿›å…¥THUDMæ–‡ä»¶å¤¹ï¼Œ[huggingface](https://huggingface.co/THUDM/chatglm3-6b?clone=true)  ä¸‹è½½  

```bash
åˆå§‹åŒ–git lfsï¼š
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs
git lfs install
git clone https://huggingface.co/THUDM/chatglm3-6b
```

æ³¨: æœ‰çš„LFSæ— æ³•é€šè¿‡git cloneä¸‹è½½ï¼Œéœ€è¦ä½¿ç”¨wget  æ–‡ä»¶é“¾æ¥ä¸‹è½½ã€‚



![huggingface](README.assets/huggingface-17049659072502.png)



### å¤šè½®å¯¹è¯æ ¼å¼

å¤šè½®å¯¹è¯å¾®è°ƒç¤ºä¾‹é‡‡ç”¨ ChatGLM3 å¯¹è¯æ ¼å¼çº¦å®šï¼Œå¯¹ä¸åŒè§’è‰²æ·»åŠ ä¸åŒ `loss_mask` ä»è€Œåœ¨ä¸€éè®¡ç®—ä¸­ä¸ºå¤šè½®å›å¤è®¡ç®— `loss`ã€‚

### æ•°æ®æ ¼å¼å’Œé¢„å¤„ç† ğŸ“Š

æˆ‘ä»¬çš„æ•°æ®æ ¼å¼éµå¾ª ChatGLM3 å¯¹è¯æ ¼å¼çº¦å®šã€‚è¯·å‚ç…§ä»¥ä¸‹æ ¼å¼æ•´ç†æ‚¨çš„å¯¹è¯æ•°æ®ï¼š

```json
jsonCopy code[
  {
    "conversations": [
      {"role": "system", "content": "<system prompt text>"},
      {"role": "user", "content": "<user prompt text>"},
      {"role": "assistant", "content": "<assistant response text>"},
      // ... å¤šè½®å¯¹è¯
    ]
  },
  // ...
]
```

**å‚è€ƒæˆ‘æ–‡ä»¶å¤¹data_processingä¸­çš„è„šæœ¬ï¼Œå…·ä½“è€Œè¨€å¯¹äºdata.csvï¼ˆ æ•°æ®å¯è§†åŒ–æ•°æ®é›†æˆ–è€…çˆ¬è™«æ¸…æ´—è¿‡çš„æ•°æ®ï¼‰æ‰§è¡Œ data_processing.pyï¼ˆæ ¹æ®è‡ªå·±æ•°æ®ä¿®æ”¹ï¼‰å¾—åˆ°jsonæ–‡ä»¶ï¼Œ ç„¶åæ‰§è¡Œformat_tool_poke.py  å¾—åˆ° jsonlæ–‡ä»¶**ã€‚

### å¾®è°ƒæ¨¡å‹ ğŸ’¡

ä»¥ä¸‹è„šæœ¬æä¾›äº†å¾®è°ƒæ¨¡å‹çš„å‚è€ƒæ–¹å¼ã€‚

```bash
./scripts/finetune_ds_multiturn.sh  # å…¨é‡å¾®è°ƒ
./scripts/finetune_pt_multiturn.sh  # P-Tuning v2 å¾®è°ƒ
```

æˆ‘è¿™é‡Œé‡‡ç”¨ P-Tuning v2 å¾®è°ƒã€‚ï¼ˆ å‚è€ƒæˆ‘å†™çš„  finetune_ps_pt_m.shï¼‰

å®˜æ–¹è¯´æ³•ï¼š

å‚è€ƒæ˜¾å­˜ç”¨é‡

- P-Tuning V2 `PRE_SEQ_LEN=128`, `DEV_BATCH_SIZE=1`, `GRAD_ACCUMULARION_STEPS=16`, `MAX_SEQ_LEN=2048` é…ç½®ä¸‹çº¦éœ€è¦ 21GB æ˜¾å­˜ã€‚
- å…¨é‡å¾®è°ƒæ—¶ï¼Œ`./scripts/finetune_ds_multiturn.sh` ä¸­çš„é…ç½®ï¼ˆ`MAX_SEQ_LEN=2048`, `DEV_BATCH_SIZE=16`, `GRAD_ACCUMULARION_STEPS=1`ï¼‰æ°å¥½ç”¨æ»¡ 4 * 80GB æ˜¾å­˜ã€‚

### æ¨ç†éªŒè¯ :anguished:

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨ç†éªŒè¯ï¼š

```python
  python inference.py     --pt-checkpoint /path/to/your/model     --model THUDM/chatglm3-6b     --tokenizer THUDM/chatglm3-6b     --pt-pre-seq-len 128     --max-new-tokens 128 \
```

-  /path/to/your/model : æŒ‡çš„æ˜¯ä½ è®­ç»ƒç»“æŸçš„æ¨¡å‹è·¯å¾„,æ¯”å¦‚  /root/autodl-tmp/project/finetune_chatmodel_demo/output/pokemon

-  finetune_chatmodel_demo æ–‡ä»¶å¤¹ä¸‹inference.py  



### æ¨ç†æ¼”ç¤º  :sunflower:

![å¯¹è¯æ¨ç†](README.assets/å¯¹è¯æ¨ç†-17049689674643.gif)

###  æ¨ç†GPUä½¿ç”¨ç‡ :mushroom:

![gpuåˆ©ç”¨å›¾](README.assets/gpuåˆ©ç”¨å›¾.png)

### æ€»ç»“ âœ¨

æˆ‘ä»¬çš„é¡¹ç›®æ—¨åœ¨æä¾›ä¸€ä¸ªè¯¦ç»†çš„è®­ç»ƒè°ƒè¯•è‡ªå·±æ•°æ®é›†çš„æ–¹æ³•ï¼Œ åœ¨ ChatGLM3 æ¡†æ¶ä¸‹å¯¹å®å¯æ¢¦æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬æä¾›äº†è¯¦ç»†çš„å®‰è£…æŒ‡å¯¼ã€æ•°æ®å¤„ç†æ­¥éª¤å’Œå¾®è°ƒç¤ºä¾‹ï¼Œä»¥å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹å’Œè¿è¡Œæ¨¡å‹ã€‚ğŸš€










## CLIPå®å¯æ¢¦å›¾åƒæ¢ç´¢

ğŸ‰ ä½¿ç”¨CLIPæ¨¡å‹æ¢ç´¢å®å¯æ¢¦çš„ä¸–ç•Œï¼æœ¬é¡¹ç›®é€šè¿‡å›¾ç‰‡ä¸å¯¹åº”çš„ä¸­æ–‡åå­—ï¼Œä½¿ç”¨å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•æ¥è¯†åˆ«å’Œåˆ†æå®å¯æ¢¦å›¾ç‰‡ã€‚é¡¹ç›®åŸºäºChinese-CLIPæ¨¡å‹ï¼Œä¸“ä¸ºå¤„ç†ä¸­æ–‡æ–‡æœ¬è€Œä¼˜åŒ–ã€‚æˆ‘ä»¬é€šè¿‡å›¾ç‰‡ä¸å›¾ç‰‡åè¿›è¡Œå¤šæ¨¡æ€æ¢ç´¢ã€‚

ä¾‹å¦‚ imgsï¼š 0001å¦™è›™ç§å­.png

è€ƒè™‘åˆ°clipå¯¹äºä¸­æ–‡æ”¯æŒä¸é‚£ä¹ˆä¼˜ç§€ã€‚æœ¬é¡¹ç›®åŸºäº [Chinese-CLIP ](https://github.com/OFA-Sys/Chinese-CLIP)ã€‚  

Chinese-CLIP æ˜¯CLIPæ¨¡å‹çš„**ä¸­æ–‡**ç‰ˆæœ¬ï¼Œä½¿ç”¨å¤§è§„æ¨¡ä¸­æ–‡æ•°æ®è¿›è¡Œè®­ç»ƒï¼ˆ~2äº¿å›¾æ–‡å¯¹ï¼‰ï¼Œæ—¨åœ¨å¸®åŠ©ç”¨æˆ·å¿«é€Ÿå®ç°ä¸­æ–‡é¢†åŸŸçš„[å›¾æ–‡ç‰¹å¾&ç›¸ä¼¼åº¦è®¡ç®—](https://github.com/OFA-Sys/Chinese-CLIP#APIå¿«é€Ÿä¸Šæ‰‹)ã€[è·¨æ¨¡æ€æ£€ç´¢](https://github.com/OFA-Sys/Chinese-CLIP#è·¨æ¨¡æ€æ£€ç´¢)ã€[é›¶æ ·æœ¬å›¾ç‰‡åˆ†ç±»](https://github.com/OFA-Sys/Chinese-CLIP#é›¶æ ·æœ¬å›¾åƒåˆ†ç±»)ç­‰ä»»åŠ¡ã€‚(å‚è€ƒChinese-Clip readme)



### å®‰è£…è¦æ±‚ ğŸ› 

å¼€å§‹æœ¬é¡¹ç›®å‰ï¼Œéœ€å…ˆæ£€æŸ¥æ˜¯å¦æ»¡è¶³ä¸‹åˆ—ç¯å¢ƒé…ç½®è¦æ±‚:

- python >= 3.6.4
- pytorch >= 1.8.0 (with torchvision >= 0.9.0)
- CUDA Version >= 10.2

è¿è¡Œä¸‹åˆ—å‘½ä»¤å³å¯å®‰è£…æœ¬é¡¹ç›®æ‰€éœ€çš„ä¸‰æ–¹åº“ã€‚

```python
pip install -r requirements.txt
```

### å¿«é€Ÿå¼€å§‹ ğŸš€

å®‰è£…Chinese-CLIPåï¼Œæ‚¨å¯ä»¥è½»æ¾åœ°è°ƒç”¨APIï¼Œè¿›è¡Œå›¾æ–‡ç‰¹å¾æå–å’Œç›¸ä¼¼åº¦è®¡ç®—ã€‚é¦–å…ˆï¼Œå®‰è£…cn_clipï¼š

```bash
# é€šè¿‡pipå®‰è£…
pip install cn_clip

# æˆ–è€…ä»æºä»£ç å®‰è£…
cd Chinese-CLIP
pip install -e .
```

å®‰è£…æˆåŠŸåï¼Œå³å¯é€šè¿‡å¦‚ä¸‹æ–¹å¼è½»æ¾è°ƒç”¨APIï¼Œä¼ å…¥æŒ‡å®šå›¾ç‰‡ï¼ˆ[ç¤ºä¾‹](https://github.com/OFA-Sys/Chinese-CLIP/blob/master/examples/pokemon.jpeg)ï¼‰å’Œæ–‡æœ¬ï¼Œæå–å›¾æ–‡ç‰¹å¾å‘é‡å¹¶è®¡ç®—ç›¸ä¼¼åº¦ï¼š

```python
import torch 
from PIL import Image

import cn_clip.clip as clip
from cn_clip.clip import load_from_name, available_models
print("Available models:", available_models())  
# Available models: ['ViT-B-16', 'ViT-L-14', 'ViT-L-14-336', 'ViT-H-14', 'RN50']

device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = load_from_name("ViT-B-16", device=device, download_root='./')
model.eval()
image = preprocess(Image.open("examples/pokemon.jpeg")).unsqueeze(0).to(device)
text = clip.tokenize(["æ°å°¼é¾Ÿ", "å¦™è›™ç§å­", "å°ç«é¾™", "çš®å¡ä¸˜"]).to(device)

with torch.no_grad():
    image_features = model.encode_image(image)
    text_features = model.encode_text(text)
    # å¯¹ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œè¯·ä½¿ç”¨å½’ä¸€åŒ–åçš„å›¾æ–‡ç‰¹å¾ç”¨äºä¸‹æ¸¸ä»»åŠ¡
    image_features /= image_features.norm(dim=-1, keepdim=True) 
    text_features /= text_features.norm(dim=-1, keepdim=True)    

    logits_per_image, logits_per_text = model.get_similarity(image, text)
    probs = logits_per_image.softmax(dim=-1).cpu().numpy()

print("Label probs:", probs)  # [[1.268734e-03 5.436878e-02 6.795761e-04 9.436829e-01]]
```

æ³¨æ„è¿™é‡Œçš„pokemon.jpeg æ˜¯Chinese-clipç›®å½•ä¸­çš„ã€‚

### è®­ç»ƒæ‚¨è‡ªå·±çš„æ•°æ®é›† ğŸŒŸ

æœ¬é¡¹ç›®æ”¯æŒä½¿ç”¨æ‚¨è‡ªå·±çš„æ•°æ®é›†è¿›è¡Œæ¨¡å‹è®­ç»ƒã€‚è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤æ¥ç»„ç»‡æ‚¨çš„ä»£ç å’Œæ•°æ®ï¼š

### ä»£ç ç»„ç»‡

ä¸‹è½½æœ¬é¡¹ç›®å, è¯·åˆ›å»ºæ–°çš„æ–‡ä»¶å¤¹ `${DATAPATH}` ä»¥å­˜æ”¾æ•°æ®é›†ã€é¢„è®­ç»ƒckptã€ä»¥åŠfinetuneäº§ç”Ÿçš„æ¨¡å‹æ—¥å¿—&ckptã€‚æ¨èå·¥ä½œåŒºç›®å½•ç»“æ„å¦‚ä¸‹ï¼š

```plaintext
Chinese-CLIP/
â”œâ”€â”€ run_scripts/
â”‚   â”œâ”€â”€ muge_finetune_vit-b-16_rbt-base.sh   #å®˜æ–¹æ˜¯å¤šå¡ï¼Œæˆ‘è¿™é‡Œä¿®æ”¹ä¸ºå•å¡
â”‚   â”œâ”€â”€ flickr30k_finetune_vit-b-16_rbt-base.sh
â”‚   â””â”€â”€ ...           # æ›´å¤šfinetuneæˆ–è¯„æµ‹è„šæœ¬...
â””â”€â”€ cn_clip/
    â”œâ”€â”€ clip/
    â”œâ”€â”€ eval/
    â”œâ”€â”€ preprocess/
    â””â”€â”€ training/

${DATAPATH}  #è¿™é‡Œæˆ‘æ”¾åœ¨ Chinese-CLIP/
â”œâ”€â”€ pretrained_weights/
â”œâ”€â”€ experiments/   #æ”¹ä¸º  ${DATAPATH}/logs/ å°±æ˜¯ Chinese-CLIP/logs
â”œâ”€â”€ deploy/	      # ç”¨äºå­˜æ”¾ONNX & TensorRTéƒ¨ç½²æ¨¡å‹
â””â”€â”€ datasets/   #  Chinese-CLIP/datasets
    â”œâ”€â”€ MUGE/     # 2G   
    â”œâ”€â”€ Flickr30k-CN/  2G å¤§å°
    â””â”€â”€ .../          # æ›´å¤šè‡ªå®šä¹‰æ•°æ®é›†...  è¿™é‡ŒåŠ å…¥pokemonæ•°æ®é›†
```



### åˆ¶ä½œè‡ªå·±çš„æ•°æ®é›†

æ‚¨å¯ä»¥åœ¨ `datasets` æ–‡ä»¶å¤¹ä¸‹æ‰¾åˆ° `pokemon` æ•°æ®é›†ã€‚ä½¿ç”¨ `data_processing` è„šæœ¬æ¥è°ƒæ•´æ‚¨çš„æ•°æ®æ ¼å¼ï¼š

- `data_t2s.py`: å¦‚æœæ‚¨çš„æ•°æ®æ˜¯ç¹ä½“ä¸­æ–‡ï¼Œä½¿ç”¨æ­¤è„šæœ¬è½¬æ¢ä¸ºç®€ä½“ä¸­æ–‡ã€‚
- `data_processing.py`: è´Ÿè´£åŠ è½½å¹¶å¤„ç†æ•°æ®ï¼Œæœ€ç»ˆç”Ÿæˆ `.tsv` å’Œ `.jsonl` æ–‡ä»¶ã€‚

### æ¨¡å‹å¾®è°ƒ

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨¡å‹å¾®è°ƒï¼š

```bash
cd Chinese-CLIP/
bash run_scripts/muge_finetune_vit-b-16_rbt-base.sh ${DATAPATH}
```

è¯·æ ¹æ®æ‚¨çš„éœ€è¦è°ƒæ•´ `muge_finetune_vit-b-16_rbt-base.sh` è„šæœ¬ã€‚

### è®­ç»ƒç»†èŠ‚

-  ä½¿ç”¨3090 24 G batch_sizeè®¾ç½®ä¸º64ï¼Œ æ˜¾å­˜å æœ‰22G,åˆå§‹epochs  accç‰¹åˆ«ä½ 1% è¿™æ ·å­ï¼Œå¤šå°æœºå­éƒ½æ˜¯è¿™ä¸ªè¡¨ç°ã€‚ åœ¨epochs 414 accåˆ°è¾¾95%, æˆ‘æ–­æ‰äº†æœåŠ¡å™¨ã€‚ å‰414epochs : [epochs-best.pt](https://pan.baidu.com/s/15bw8LKaEuHX2u5XiIL6OEg?pwd=3032 )  æå–ç  ï¼š 3032 

-  V100  32 G   batch_sizeè®¾ç½®ä¸º 128   æ˜¾å­˜å æœ‰26Gï¼Œ åˆå§‹acc 83% ï¼Œè®­ç»ƒ30 epochs  text2imge å’Œ imge2textéƒ½åˆ°è¾¾ 98%ä½œç”¨ï¼Œ å½“epochs=50   æ—¶å€™text2imge å’Œ imge2text è¶…è¿‡99%  ï¼Œå‰ 50epochs :    [epochs-best.pt ](https://pan.baidu.com/s/14gP-eM7Pegg6quEpEpFgsw )  æå–ç ï¼šgogf 

 

### æ¨ç†ä¸è¯„ä¼° ğŸ•µï¸â€â™‚ï¸

ç”±äºChinese-clipå¹¶æ²¡æœ‰è¯´æ˜è‡ªå·±è®­ç»ƒæ•°æ®åæ¨ç†çš„ç»†èŠ‚ ï¼Œæ¥ä¸‹æ¥çš„æ¨ç†ç»†èŠ‚å¯ä»¥è®¤ä¸ºæ˜¯åŸé¡¹ç›®çš„è¡¥å……ã€‚

#### 1.å®˜æ–¹ä»£ç æ¨ç†è‡ªå·±è®­ç»ƒé›†ä¸­çš„å›¾ç‰‡

```python

*import* torch 

*from* PIL *import* Image



*import* cn_clip.clip *as* clip

*from* cn_clip.clip *import* load_from_name, available_models

print("Available models:", available_models())  

*# Available models: ['ViT-B-16', 'ViT-L-14', 'ViT-L-14-336', 'ViT-H-14', 'RN50']*



device *=* "cuda" *if* torch.cuda.is_available() *else* "cpu"

model, preprocess *=* load_from_name("ViT-B-16", *device**=*device, *download_root**=*'./')

model.eval()

image *=* preprocess(Image.open("imgs/çš®å¡ä¸˜.png").convert("RGBA")).unsqueeze(0).to(device)  *#Label probs: [[0.003006 0.974   0.01017  0.01265 ]]*

*# image = preprocess(Image.open("imgs/çš®å¡ä¸˜.png")).unsqueeze(0).to(device)*

text *=* clip.tokenize(["æ°å°¼é¾Ÿ", "å¦™è›™ç§å­", "å°ç«é¾™", "çš®å¡ä¸˜"]).to(device)



*with* torch.no_grad():

  image_features *=* model.encode_image(image)

  text_features *=* model.encode_text(text)

  *# å¯¹ç‰¹å¾è¿›è¡Œå½’ä¸€åŒ–ï¼Œè¯·ä½¿ç”¨å½’ä¸€åŒ–åçš„å›¾æ–‡ç‰¹å¾ç”¨äºä¸‹æ¸¸ä»»åŠ¡*

  image_features */=* image_features.norm(*dim**=-*1, *keepdim**=*True) 

  text_features */=* text_features.norm(*dim**=-*1, *keepdim**=*True)   



  logits_per_image, logits_per_text *=* model.get_similarity(image, text)

  probs *=* logits_per_image.softmax(*dim**=-*1).cpu().numpy()



print("Label probs:", probs)     # Label probs: [[0.002913 0.974    0.01017  0.01266 ]]  é¢„æµ‹ä¸ºå¦™è›™ç§å­  æ˜æ˜¾é”™è¯¯
```

 ` Available models: ['ViT-B-16', 'ViT-L-14', 'ViT-L-14-336', 'ViT-H-14', 'RN50'] Loading vision model config from /root/autodl-tmp/project/cn_clip/clip/model_configs/ViT-B-16.json Loading text model config from /root/autodl-tmp/project/cn_clip/clip/model_configs/RoBERTa-wwm-ext-base-chinese.json Model info {'embed_dim': 512, 'image_resolution': 224, 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 12, 'text_type_vocab_size': 2} Label probs: [[0.002913 0.974    0.01017  0.01266 ]]` 



#### 2. å¾®è°ƒåä½¿ç”¨epochs_best.ptæ¨ç†è‡ªå·±çš„æ•°æ®é›†

```python
 import torch
import torch.nn.functional as F
import cn_clip.clip as clip
from PIL import Image

# åŠ è½½å¾®è°ƒåçš„æ¨¡å‹æƒé‡
model_path = 'epoch_latest.pt'
saved_model = torch.load(model_path, map_location=torch.device('cpu'))
model_state_dict = saved_model['state_dict']

# è°ƒæ•´çŠ¶æ€å­—å…¸çš„é”®
adjusted_state_dict = {}
for key in model_state_dict.keys():
    new_key = key[7:] if key.startswith('module.') else key
    adjusted_state_dict[new_key] = model_state_dict[key]

# åˆ›å»ºæ¨¡å‹å®ä¾‹
device = "cuda" if torch.cuda.is_available() else "cpu"
model, preprocess = clip.load_from_name("ViT-B-16", device=device)

# åŠ è½½è°ƒæ•´åçš„çŠ¶æ€å­—å…¸
try:
    model.load_state_dict(adjusted_state_dict)
except RuntimeError as e:
    print("Error:", e)
    model.load_state_dict(adjusted_state_dict, strict=False)

# è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
model.eval()

# å›¾åƒé¢„å¤„ç†
image_path = "imgs/çš®å¡ä¸˜.png"
image = preprocess(Image.open(image_path).convert("RGBA")).unsqueeze(0).to(device)

# æ–‡æœ¬å¤„ç†
text = clip.tokenize(["æ°å°¼é¾Ÿ", "å¦™è›™ç§å­", "å°ç«é¾™", "çš®å¡ä¸˜"]).to(device)

# æ¨ç†
with torch.no_grad():
    image_features, text_features, logit_scale = model(image, text)

    # å½’ä¸€åŒ–ç‰¹å¾
    image_features /= image_features.norm(dim=-1, keepdim=True)
    text_features /= text_features.norm(dim=-1, keepdim=True)

    # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
    logits_per_image = logit_scale * image_features @ text_features.t()

    # è½¬æ¢ä¸ºæ¦‚ç‡
    probs_per_image = F.softmax(logits_per_image, dim=-1).cpu().numpy()

print("Label probabilities:", probs_per_image) #[[0.e+00 0.e+00 6.e-08 1.e+00]] é¢„æµ‹ä¸ºçš®å¡ä¸˜ ï¼

```

`Loading vision model config from /root/autodl-tmp/project/cn_clip/clip/model_configs/ViT-B-16.json Loading text model config from /root/autodl-tmp/project/cn_clip/clip/model_configs/RoBERTa-wwm-ext-base-chinese.json Model info {'embed_dim': 512, 'image_resolution': 224, 'vision_layers': 12, 'vision_width': 768, 'vision_patch_size': 16, 'vocab_size': 21128, 'text_attention_probs_dropout_prob': 0.1, 'text_hidden_act': 'gelu', 'text_hidden_dropout_prob': 0.1, 'text_hidden_size': 768, 'text_initializer_range': 0.02, 'text_intermediate_size': 3072, 'text_max_position_embeddings': 512, 'text_num_attention_heads': 12, 'text_num_hidden_layers': 12, 'text_type_vocab_size': 2} Label probabilities: [[0.e+00 0.e+00 6.e-08 1.e+00]]`

ä¸€ä¸ªæé†’ï¼š å½“ä½ è®­ç»ƒå®Œæ¨¡å‹è¿›è¡Œæ¨ç†æ—¶å€™ï¼Œè®­ç»ƒåptæƒé‡çš„é¡ºåºä¼šé”™ä¹± ï¼Œ**éœ€è¦åŠ è½½è°ƒæ•´åçš„çŠ¶æ€å­—å…¸** ã€‚



