# ChatGLM3-6B å¤šè½®å¯¹è¯å¾®è°ƒå®å¯æ¢¦æ•°æ®é›† ğŸš€

è¿™ä¸ªé¡¹ç›®æ˜¯åŸºäº [ChatGLM3](https://github.com/THUDM/ChatGLM3) çš„æ‰©å±•ï¼Œä¸“æ³¨äºåˆ©ç”¨å®å¯æ¢¦æ•°æ®é›†å¯¹èŠå¤©æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬ä½¿ç”¨ RTX 4090 24G è¿›è¡Œè®­ç»ƒï¼Œç¡®ä¿é«˜æ•ˆçš„æ¨¡å‹æ€§èƒ½

### ç¯å¢ƒå®‰è£… ğŸ› ï¸

é¦–å…ˆéœ€è¦ä¸‹è½½ChatGLM3-6B å®˜æ–¹ä»“åº“ï¼š

```
git clone https://github.com/THUDM/ChatGLM3
cd ChatGLM3
```

ç„¶åä½¿ç”¨ pip å®‰è£…ä¾èµ–ï¼š

```
pip install -r requirements.txt
```



**æ›¿æ¢ `finetune_chatmodel_demo` æ–‡ä»¶å¤¹**: å°†å®˜æ–¹çš„ `finetune_chatmodel_demo` æ–‡ä»¶å¤¹æ›¿æ¢ä¸ºæœ¬é¡¹ç›®æä¾›çš„ç‰ˆæœ¬ã€‚

è¿è¡Œç¤ºä¾‹éœ€è¦ `python>=3.10`ï¼Œé™¤åŸºç¡€çš„ `torch` ä¾èµ–å¤–ï¼Œç¤ºä¾‹ä»£ç è¿è¡Œè¿˜éœ€è¦ä¾èµ–

```
pip install requirements.txt
```



 è¿›å…¥THUDMæ–‡ä»¶å¤¹ï¼Œ[huggingface](https://huggingface.co/THUDM/chatglm3-6b?clone=true)  ä¸‹è½½  

```

åˆå§‹åŒ–git lfsï¼š
curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash
sudo apt-get install git-lfs
git lfs install
git clone https://huggingface.co/THUDM/chatglm3-6b
```

æ³¨: æœ‰çš„LFSæ— æ³•é€šè¿‡git cloneä¸‹è½½ï¼Œéœ€è¦ä½¿ç”¨wget  æ–‡ä»¶é“¾æ¥ä¸‹è½½ã€‚



![huggingface](readme.assets/huggingface-17049659072502.png)



## å¤šè½®å¯¹è¯æ ¼å¼

å¤šè½®å¯¹è¯å¾®è°ƒç¤ºä¾‹é‡‡ç”¨ ChatGLM3 å¯¹è¯æ ¼å¼çº¦å®šï¼Œå¯¹ä¸åŒè§’è‰²æ·»åŠ ä¸åŒ `loss_mask` ä»è€Œåœ¨ä¸€éè®¡ç®—ä¸­ä¸ºå¤šè½®å›å¤è®¡ç®— `loss`ã€‚

## æ•°æ®æ ¼å¼å’Œé¢„å¤„ç† ğŸ“Š

æˆ‘ä»¬çš„æ•°æ®æ ¼å¼éµå¾ª ChatGLM3 å¯¹è¯æ ¼å¼çº¦å®šã€‚è¯·å‚ç…§ä»¥ä¸‹æ ¼å¼æ•´ç†æ‚¨çš„å¯¹è¯æ•°æ®ï¼š

```
jsonCopy code[
  {
    "conversations": [
      {"role": "system", "content": "<system prompt text>"},
      {"role": "user", "content": "<user prompt text>"},
      {"role": "assistant", "content": "<assistant response text>"},
      // ... å¤šè½®å¯¹è¯
    ]
  },
  // ...
]
```

**å‚è€ƒæˆ‘æ–‡ä»¶å¤¹data_processingä¸­çš„è„šæœ¬ï¼Œå…·ä½“è€Œè¨€å¯¹äºdata.csvï¼ˆ æ•°æ®å¯è§†åŒ–æ•°æ®é›†æˆ–è€…çˆ¬è™«æ¸…æ´—è¿‡çš„æ•°æ®ï¼‰æ‰§è¡Œ data_processing.pyï¼ˆæ ¹æ®è‡ªå·±æ•°æ®ä¿®æ”¹ï¼‰å¾—åˆ°jsonæ–‡ä»¶ï¼Œ ç„¶åæ‰§è¡Œformat_tool_poke.py  å¾—åˆ° jsonlæ–‡ä»¶**ã€‚

## å¾®è°ƒæ¨¡å‹ ğŸ’¡

ä»¥ä¸‹è„šæœ¬æä¾›äº†å¾®è°ƒæ¨¡å‹çš„å‚è€ƒæ–¹å¼ã€‚

```
./scripts/finetune_ds_multiturn.sh  # å…¨é‡å¾®è°ƒ
./scripts/finetune_pt_multiturn.sh  # P-Tuning v2 å¾®è°ƒ
```

æˆ‘è¿™é‡Œé‡‡ç”¨ P-Tuning v2 å¾®è°ƒã€‚ï¼ˆ å‚è€ƒæˆ‘å†™çš„  finetune_ps_pt_m.shï¼‰

å®˜æ–¹è¯´æ³•ï¼š

å‚è€ƒæ˜¾å­˜ç”¨é‡

- P-Tuning V2 `PRE_SEQ_LEN=128`, `DEV_BATCH_SIZE=1`, `GRAD_ACCUMULARION_STEPS=16`, `MAX_SEQ_LEN=2048` é…ç½®ä¸‹çº¦éœ€è¦ 21GB æ˜¾å­˜ã€‚
- å…¨é‡å¾®è°ƒæ—¶ï¼Œ`./scripts/finetune_ds_multiturn.sh` ä¸­çš„é…ç½®ï¼ˆ`MAX_SEQ_LEN=2048`, `DEV_BATCH_SIZE=16`, `GRAD_ACCUMULARION_STEPS=1`ï¼‰æ°å¥½ç”¨æ»¡ 4 * 80GB æ˜¾å­˜ã€‚

### æ¨ç†éªŒè¯ :anguished:

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨ç†éªŒè¯ï¼š

```
  python inference.py     --pt-checkpoint /path/to/your/model     --model THUDM/chatglm3-6b     --tokenizer THUDM/chatglm3-6b     --pt-pre-seq-len 128     --max-new-tokens 128 \
```

-  /path/to/your/model : æŒ‡çš„æ˜¯ä½ è®­ç»ƒç»“æŸçš„æ¨¡å‹è·¯å¾„,æ¯”å¦‚  /root/autodl-tmp/project/finetune_chatmodel_demo/output/pokemon

- finetune_chatmodel_demo æ–‡ä»¶å¤¹ä¸‹inference.py  



### æ¨ç†æ¼”ç¤º  :sunflower:

![å¯¹è¯æ¨ç†](readme.assets/å¯¹è¯æ¨ç†-17049689674643.gif)

###  æ¨ç†GPUä½¿ç”¨ç‡ :mushroom:

![gpuåˆ©ç”¨å›¾](readme.assets/gpuåˆ©ç”¨å›¾.png)

## æ€»ç»“ âœ¨

æˆ‘ä»¬çš„é¡¹ç›®æ—¨åœ¨æä¾›ä¸€ä¸ªè¯¦ç»†çš„è®­ç»ƒè°ƒè¯•è‡ªå·±æ•°æ®é›†çš„æ–¹æ³•ï¼Œ åœ¨ ChatGLM3 æ¡†æ¶ä¸‹å¯¹å®å¯æ¢¦æ•°æ®é›†è¿›è¡Œå¾®è°ƒã€‚æˆ‘ä»¬æä¾›äº†è¯¦ç»†çš„å®‰è£…æŒ‡å¯¼ã€æ•°æ®å¤„ç†æ­¥éª¤å’Œå¾®è°ƒç¤ºä¾‹ï¼Œä»¥å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹å’Œè¿è¡Œæ¨¡å‹ã€‚ğŸš€